#!/bin/sh

# 'fb_' stands for 'FEAST benchmark'.
# Variables are written in capital letters if used globally.


# Initialisations
ALLTESTS=
BENCHMARKRUNSCRIPT=runtests
DOSENDMAIL=
EMAILADDRESS=
GNUMAKE=
JOBFILEPREFIX="feat2job"
MODULESLOADED=
OVERWRITE_LOG_DIRECTORY=
NTASKS=
WALLCLOCKLIMIT="00:40:00"
NOSCHEDULE=0
case "`hostname -f`" in
    *.lidocluster.hp) 
	# Torque on LiDO-2 is configured to believe every node has
	# only four cores. Despite it having 8. But using 8 cores
	# would give a serious performance penalty (memory wall) given
	# that there is only one memory bus per node.
	CORESPERNODE=4;
	PPN=":ppn=4";
	ultralong_queue="ultralong_eth"
	;;
    *.cvos.cluster)
	CORESPERNODE=2;
	PPN=":ppn=2";
	ultralong_queue="neternal_eth"
	;;
esac
AFTERJOB=""


# ==================================================================
# IMPORTANT
# ==================================================================
# It is assumed this script is called from a FEAT2 benchmark
# directory.  This assumption is not only made here, but also later
# as the Makefile in a fbenchmark2 directory (whatever its actual
# name is) is needed to create a 'runtests' script. The library
# function fb_ensureCorrectWorkingDir even checks whether that's the
# case.


# ==================================================
# = Load library with functions needed for         =
# = every scheduling script (NEC, LiDO, JUMP etc.) =
# ================================================== 
. include/lib_for_xxx_schedule_tests || exit 1


# Three arrays containing relevant LiDO queue settings
# Indices must always be the same:
# 0 = short_*  ,  1 = med_*  ,  2 = long_*
#
# Names of queues, maximum wallclock times (in seconds) and 
# maximum number of nodes currently available (= online nodes)
declare -a eth[3], ib[2]
declare -a eth_wallclockseconds[3], ib_wallclockseconds[2]
declare -a eth_maxnodes[3], ib_maxnodes[2]


#  Function: Query PBS to find out about available nodes and maximum walltime per queue
fb_queryPBSLiDO() {
    eth[0]="short_eth"
    eth[1]="med_eth"
    eth[2]="long_eth"
    eth[3]=${ultralong_queue}
    ib[0]="short_ib"
    ib[1]="med_ib"
    ib[2]="long_ib"

    # Create temporary file (with unique file name)
    qmgr=`mktemp`
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error: Creating temporary file failed. Script cancelled.
EOF
	exit 2
    fi

    # Query PBS queue manager and store result in temporary file
    qmgr -c 'list queue @master' > ${qmgr}
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error: Could not query PBS manager for available resources. Script cancelled.
EOF
	exit 3
    fi

    # Create temporary file (with unique file name)
    sedFileSuppressOfflineNodes="`mktemp`"".sed"
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error: Creating temporary file failed. Script cancelled.
EOF
	exit 4
    fi

    # Query PBS for offline nodes, transform the output into sed instructions
    # (that remove any occurrence of offline nodes from input strings) and
    # store it to a temporary file
    pbsnodes -l | grep offline | sed 's/^\([^ ]*\).*$/s\/\1+*\/\/;/' > ${sedFileSuppressOfflineNodes}
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error: Could not query PBS for offline nodes. Script cancelled.
EOF
	exit 5
    fi

    # Define a smaller helper routine for code repeatedly needed
    fb_getSettingsForQueue() {
	queue="$1"  # IN
        egrep "^(Queue |[[:space:]]+acl_hosts|[[:space:]]+[^=]+\.lidocluster\.hp|[[:space:]]+resources_max.walltime)" ${qmgr} | \
 		# (Sed:) Unwrap acl_hosts list.
		sed ':x; /,$/ { N; s/\n[ ]*//; tx}' | \
 		# Turn output into one line per queue
 		grep -v "^Queue default" | \
 		sed 'N; N; s/\n//g;' | \
		# Suppress offline nodes
		sed -f ${sedFileSuppressOfflineNodes} | \
		# Extract current queue
		grep -w ${queue}
    }

    # eth queue
    for i in 0 1 2 3; do
	queue=${eth[$i]};
	# Determine maximum wall clock time
	eth_wallclockseconds[$i]=`fb_getSettingsForQueue $queue | awk '{print $NF}' | awk -F: '{print $1*3600+$2*60+$3}'`
	# Determine maximum number of nodes available
	eth_maxavailnodes[$i]=`fb_getSettingsForQueue $queue | sed -e 's/^.*acl_hosts = \([^ \t]*\).*/\1/; s/[+,]/ /g;' | wc -w`
    done

    # ib queue
    for i in 0 1 2; do
	queue=${ib[$i]};
	# Determine maximum wall clock time
	ib_wallclockseconds[$i]=`fb_getSettingsForQueue $queue | awk '{print $NF}' | awk -F: '{print $1*3600+$2*60+$3}'`
	# Determine maximum number of nodes available
	ib_maxavailnodes[$i]=`fb_getSettingsForQueue $queue | sed -e 's/^.*acl_hosts = \([^ \t]*\).*/\1/; s/[+,]/ /g;' | wc -w`
    done

    rm -f ${qmgr} ${sedFileSuppressOfflineNodes}
}


#  Function: Determine most suitable queue depending on node, walltime and interconnect requirements
fb_determineQueue() {
    nodes="$1"      # IN (format: integer)
    queuetype="$3"  # IN (valid: "_eth" or "_ib")

    walltimeseconds="`echo $2 | awk -F: '{print $1*3600+$2*60+$3}'`"   # IN (format: hh:mm:ss)


    # Check ethernet queues
    if test "${queuetype}" = "_eth"; then 
	for i in 0 1 2 3; do
	    queue=${eth[$i]};
	    # Check whether enough nodes in queue available
	    if test ${nodes} -le ${eth_maxavailnodes[$i]}; then
		# Check whether wall time limits are not exceeded
		if test ${walltimeseconds} -le ${eth_wallclockseconds[$i]}; then
		    echo ${queue};
		    return;
		fi
	    fi
	done
    fi


    # Check infiniband queues
    if test "${queuetype}" = "_ib"; then 
	for i in 0 1 2; do
	    queue=${ib[$i]};
	    # Check whether enough nodes in queue available
	    if test ${nodes} -le ${ib_maxavailnodes[$i]}; then
		# Check whether wall time limits are not exceeded
		if test ${walltimeseconds} -le ${ib_wallclockseconds[$i]}; then
		    echo ${queue};
		    return;
		fi
	    fi
	done
    fi
}


#  Function: Create a jobfile for LiDO for a given test ID
fb_createJobfileLiDO() {
    benchmarktest="$1"  # IN
    file="$2"           # IN

    fb_createRuntestsScript "$benchmarktest"
    if [ $? -ne 0 ]; then
	return 1
    fi

    fb_getNTASKS
    if [ $? -ne 0 ]; then
	return 2
    fi

    # Only allocate complete nodes to prevent that some other
    # cluster user influences this job. Other processes possibly
    # use much more ressources than available (e.g. more memory than 
    # available => swapping, cpu threading => less cpu for us,
    # network card flooding, whatever else)
    nodes=`expr $NTASKS / $CORESPERNODE`;
    # If number of CPUs per node ($CORESPERNODE) is not divisor of the 
    # number of processes requested, then there has been an arithmetic 
    # remainder of the devision and we need one more (incompletely used) 
    # node.
    if [ `expr $NTASKS % $CORESPERNODE` -ne 0 ]; then
	nodes=`expr $nodes + 1`
    fi
    pbsOptionNodes="#PBS -l nodes=$nodes$PPN"

    # Send mail on job begin, abort and end?
    pbsOptionMail=""
    if [ "$DOSENDMAIL" -eq "1" ]; then
      pbsOptionMail="#PBS -m bae"
    fi
    
    # Let the job depend on another job?
    pbsOptionAfter=""
    if [ "$AFTERJOB" != "" ]; then
      pbsOptionAfter="#PBS -W depend=afterok:$AFTERJOB"
    fi

    # Support for OpenMPI + Infiniband, OpenMPI + GigabitEthernet
    # and LAM/MPI + GigabitEthernet.
    # Detect which MPI flavour is currently in use.
    # Add according settings to the jobfile (!), not a user's rc file.
    # Otherwise it is not possible to add GE jobs with LAM/MPI and
    # OpenMPI+IB jobs at the same time to the queue. Nor would
    # it be possible to use the same MPI flavour, but different
    # compilers at the same time as all would share the same rc file.
    sedQueueingSystem=LIDO
#    sedExecMode=PBSQUEUED
    envSetting=""
    if [ -n "$LOADEDMODULES" ]; then
	# Here enters hard-coded knowledge about maximum walltimes
	# of queues of LiDO (the server could be queries dynamically
	# for maximum walltimes, but this way it is easier.)
	case ":$LOADEDMODULES" in
	    *:mpich/ge/*)
		echo "$0: Using MPICH."
		sedMPIEnv=MPICH
		pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		interconnect=ethernet
		;;
	    *:open-mpi/ib/*|*:openmpi/ib/*)
		echo "$0: Using OpenMPI."
		sedMPIEnv=OpenMPI
		pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_ib"`
		envSetting="OMPI_MCA_btl=openib,self,sm; export OMPI_MCA_btl"
		interconnect=infiniband
		;;
	    *:open-mpi/ge/*|*:openmpi/ge/*)
		echo "$0: Using OpenMPI."
		sedMPIEnv=OpenMPI
		pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		envSetting="OMPI_MCA_btl=tcp,self,sm; export OMPI_MCA_btl"
		interconnect=ethernet
		;;
	    *:lam/*)
		echo "$0: Using LAM/MPI."
		sedMPIEnv=LAMMPI
		pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		envSetting="OMPI_MCA_btl=tcp,self,sm; export OMPI_MCA_btl"
		interconnect=ethernet
		;;
	    *:mvapich/*)
		echo "$0: Using MVAPICH."
		sedMPIEnv=MVAPICH
		pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_ib"`
		interconnect=infiniband
		;;
	    *)
		# No MPI module loaded
		echo "$0: No MPI required."
		sedMPIEnv=not-needed-as-feat2-is-serial-only
		pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		interconnect=ethernet
		;;
	esac

	# Check whether we got a valid queue
	if test -z "${pbsOptionQueue}"; then
	    if test -z "${interconnect}"; then
		interconnect=">>!!>> (none set) <<!!<<"
	    fi
	    cat <<EOF 1>&2
$0: Error: No queue available that satisfied the node, wallclock and 
$0: interconnect requirements:
$0:   nodes          >= ${nodes}
$0:   wallclock time >= ${WALLCLOCKLIMIT}
$0:   interconnect    : ${interconnect}
EOF
	    return 3
	else
	    echo "$0: Trying to enqueue to <${pbsOptionQueue}>."
	fi

	# Now, it is known which is the target queue.
	# Check whether queue is enabled/disabled.
	queueState="`qstat -Q $pbsOptionQueue | tail -1 | awk '{print \$4}'`"
	if [ "$queueState""x" = "nox" ]; then
	    cat <<EOF 1>&2
$0: Error: Queue $pbsOptionQueue is currently closed, job scheduling
$0: is not possible. Script cancelled.
EOF
	    exit 6
	fi

    # $LOADEDMODULES not set
    else
	cat <<EOF 1>&2
$0: Error: \$LOADEDMODULES not set. Job files cannot be created.
EOF
	exit 7
    fi

		# Evaluate command line parameter options
		#
    # Send mail on job begin, abort and end?
    pbsOptionMail=""
    if [ "$DOSENDMAIL" -eq "1" ]; then
      pbsOptionMail="#PBS -m bae"
    fi
    
    # Let the job depend on another job?
    pbsOptionAfter=""
    if [ "$AFTERJOB" != "" ]; then
      pbsOptionAfter="#PBS -W depend=afterok:$AFTERJOB"
    fi
		
    # Now, create the jobfile.
    cat <<EOF > $file
#!/bin/sh

#PBS -l walltime=$WALLCLOCKLIMIT
$pbsOptionNodes
#PBS -q $pbsOptionQueue
#PBS -o $PWD/logs/output.$benchmarktest
# join standard output and error streams
#PBS -j oe
#PBS -M $EMAILADDRESS
$pbsOptionMail
$pbsOptionAfter

cd $PWD

EOF
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error while creating jobfile.
EOF
	exit 8
    fi


    # Add environment settings to jobfile
    echo "$envSetting" >> $file
    echo >> $file
    fb_addModuleInstructions >> $file
    echo >> $file


    # Add the content of our runtests script to the jobfile, but
    # * omit the first lines (i.e. the shebang, leading comments)
    # * set execution mode to PBSQUEUED
    # * set MPI environment to use
#         s|^LOGDIR=[ ]*\.|LOGDIR=$sedLogDir|i;
#         s|^EXECMODE=PARALLEL|EXECMODE=$sedExecMode|i; \
    sed -e \
	"1,2d; \
         s|^QUEUEINGSYSTEM=[ ]*$|QUEUEINGSYSTEM=$sedQueueingSystem|i; \
         s|^MPIENV=[ ]*$|MPIENV=$sedMPIEnv|i;" $BENCHMARKRUNSCRIPT \
	>> $file


    # Make jobfile executable
    chmod 750 $file

    echo $0": Jobfile <$jobfile> created."
}


#  Function: Create jobfiles for LiDO for all given test IDs, bypassing the
#  usual mechanism to avoid repeated calls of 'make create-script' which slows
#  processing down by an order of magnitude (because both the initialisation
#  step of invoking make is expensive as well as repeatedly parsing all *.fbdef
#  files given the large amount of test definitions we set up by now)
fb_fastCreateAndSubmitJobfilesLiDO() {
    jobfileprefix="$1"   # IN

    # Check whether GNUmakefile is available (i.e. whether configure has been run)
    if [ ! -s GNUmakefile ]; then
	cat <<EOF 1>&2
$0: Error: No GNUmakefile found. Please run './configure' first.
EOF
	exit 9
    fi

    echo $0": Creating all jobfiles at once."

    # Support for 
    # * OpenMPI, 
    # * LAM/MPI, 
    # * MPICH,
    # * MVAPICH,
    # * plain serial
    # Detect which MPI flavour is currently in use.
    # Add according settings to the jobfile (!), not a user's rc file.
    # Otherwise it is not possible to add GE jobs with LAM/MPI and
    # OpenMPI+IB jobs at the same time to the queue. Nor would
    # it be possible to use the same MPI flavour, but different
    # compilers at the same time as all would share the same rc file.
    sedQueueingSystem=LIDO
    envSetting=""
    if [ -n "$LOADEDMODULES" ]; then
	# Here enters hard-coded knowledge about maximum walltimes
	# of queues of LiDO (the server could be queries dynamically
	# for maximum walltimes, but this way it is easier.)
	case ":$LOADEDMODULES" in
	    *:mpich/*)
		echo "$0: Using MPICH for all job files."
		sedMPIEnv=MPICH
		;;
	    *:open-mpi/*|*:openmpi/*)
		echo "$0: Using OpenMPI for all job files."
		sedMPIEnv=OpenMPI
		;;
	    *:lam/*)
		echo "$0: Using LAM/MPI for all job files."
		sedMPIEnv=LAMMPI
		envSetting="OMPI_MCA_btl=tcp,self,sm; export OMPI_MCA_btl"
		;;
	    *:mvapich/*)
		echo "$0: Using MVAPICH for all job files."
		sedMPIEnv=MVAPICH
		;;
	    *)
		# No MPI module loaded
		echo "$0: MPI not required for any job file."
		sedMPIEnv=not-needed-as-feat2-is-serial-only
		;;
	esac

    # $LOADEDMODULES not set
    else
	cat <<EOF 1>&2
$0: Error: \$LOADEDMODULES not set. Job files cannot be created.
EOF
	exit 10
    fi


    echo $0": Creating template for all job files..."
    # Create a unique temporary file
    # (Unfortunately 'mktemp' does not support suffixes.
    #  So, get a temporary name, append the suffix ".fbconf", check whether
    #  such a file already exists. If so, remove the temporary file created
    #  by mktemp (the one without the suffix), create a new one and repeat 
    #  the test.)
    tmpfile="`mktemp feast.benchmark.schedulefile.XXXXX`";
    trap "rm -f ${tmpfile}; exit 11" 2 3 9
    while test -e ${tmpfile}.fbconf; do
	rm -f ${tmpfile}
	tmpfile="`mktemp feast.benchmark.schedulefile.XXXXX`";
    done
    rm -f ${tmpfile}
    tmpfile="${tmpfile}.fbconf";
    echo $ALLTESTS | tr ' ' '\n' > $tmpfile;

    # Create part of job scripts that is identical for all tests (for a given
    # choice of MPI/no MPI and build ID)
    $GNUMAKE create-script-header
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error while creating template for job files.
EOF
	rm -f $BENCHMARKRUNSCRIPT
	exit 12
    fi

    # Already patch the master runtests script for execution on LiDO:
    # * omit the first lines (i.e. the shebang, leading comments)
    # * set queueing system and MPI env based on loaded modules.
    sed -i -e \
	        "1,2d; \
		 s|^QUEUEINGSYSTEM=[ ]*$|QUEUEINGSYSTEM=$sedQueueingSystem|i; \
		 s|^MPIENV=[ ]*$|MPIENV=$sedMPIEnv|i;" $BENCHMARKRUNSCRIPT
    echo $0": Creating template for all job files... Done."

    # Duplicate header for all jobfiles to be created
    echo $0": Cloning template job file..."
    trap "rm -f ${tmpfile} _tmp_.$BENCHMARKRUNSCRIPT.*; exit 13" 2 3 9
    for testid in $ALLTESTS
    do
	cp -fp $BENCHMARKRUNSCRIPT _tmp_.$BENCHMARKRUNSCRIPT.$testid
    done
    if [ $? -ne 0 ]; then
	cat <<EOF 1>&2
$0: Error while cloning template job file.
EOF
	rm -f $BENCHMARKRUNSCRIPT _tmp_.$BENCHMARKRUNSCRIPT.*
	exit 14
    fi
    echo $0": Cloning template job file... Done."

    # Now, replicate the actions of the make target 'create-script-body'
    #
    # Determine whether or not to use MPI
    MPI=`$GNUMAKE .mpi`
    #
    # Determine build ID (without MPI token)
    ID=`$GNUMAKE .idonly`
    #
    # Call the script that includes the appropriate environment variables for
    # a given test, but unlike in the GNUmakefile call it with additional command
    # line parameters instructing it to not write to screen, but to append
    # directly to the temporary files just created.
    export ID MPI OVERWRITE_LOG_DIRECTORY;
    include/create_script.pl --append-to-files "_tmp_.$BENCHMARKRUNSCRIPT." $tmpfile
    rm $tmpfile
    trap "rm -f _tmp_.$BENCHMARKRUNSCRIPT.*; exit 15" 2 3 9

    # Now, turn all these temporary files into proper PBS jobscripts
    for testid in $ALLTESTS
    do
	# Ignore commented out test IDs - create_script.pl has, too.
	# So, there is no point in listing them among tests that had errors.
	if test "`echo $testid | cut -c1`" = "#"; then 
	    rm -f $tmpjobfile;
	    continue;
	fi
	jobfile="$jobfileprefix.$testid.sh"
	tmpjobfile="_tmp_.$BENCHMARKRUNSCRIPT.$testid"
	if diff -q $BENCHMARKRUNSCRIPT $tmpjobfile 1>/dev/null; then
	    # Files differ, so include/create_script.pl has really 
	    # appended something, i.e. test ID has no errors.
	    testIDsWithErrors="$testIDsWithErrors $testid"
	    rm -f $tmpjobfile;

	else
	    echo $0": Creating jobfile for <$testid>."

	    # The still remaining action of the make target 'create-script':
	    # Add footer function to temporary jobfile
	    (echo; echo fb_footer; echo; ) >> $tmpjobfile

	    fb_getNTASKS $tmpjobfile
	    if [ $? -ne 0 ]; then
		echo $0": An error occurred creating the jobfile <$jobfile>."
		testIDsWithErrors="$testIDsWithErrors $testid"
		rm -f $tmpjobfile
		continue
	    fi

	    # Only allocate complete nodes to prevent that some other
	    # cluster user influences this job. Other processes possibly
	    # use much more ressources than available (e.g. more memory than 
	    # available => swapping, cpu threading => less cpu for us,
	    # network card flooding, whatever else)
	    nodes=`expr $NTASKS / $CORESPERNODE`;
	    # If number of CPUs per node ($CORESPERNODE) is not divisor of the 
	    # number of processes requested, then there has been an arithmetic 
	    # remainder of the devision and we need one more (incompletely used) 
	    # node.
	    if [ `expr $NTASKS % $CORESPERNODE` -ne 0 ]; then
		nodes=`expr $nodes + 1`
	    fi
	    pbsOptionNodes="#PBS -l nodes=$nodes$PPN"
	
	    # Support for 
	    # * OpenMPI + {Infiniband, GigabitEthernet},
	    # * LAM/MPI + GigabitEthernet,
	    # * MPICH + GigabitEthernet,
	    # * MVAPICH + Infiniband.
	    # Detect which MPI flavour is currently in use.
	    # Add according settings to the jobfile (!), not a user's rc file.
	    # Otherwise it is not possible to add GE jobs with LAM/MPI and
	    # OpenMPI+IB jobs at the same time to the queue. Nor would
	    # it be possible to use the same MPI flavour, but different
	    # compilers at the same time as all would share the same rc file.
	    envSetting=""
	    # Here enters hard-coded knowledge about maximum walltimes
            # of queues of LiDO (the server could be queries dynamically
	    # for maximum walltimes, but this way it is easier.)
	    case ":$LOADEDMODULES" in
		*:mpich/ge/*)
		    pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		    interconnect=ethernet
		    ;;
		*:open-mpi/ib/*|*:openmpi/ib/*)
		    pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_ib"`
		    envSetting="OMPI_MCA_btl=openib,self,sm; export OMPI_MCA_btl"
		    interconnect=infiniband
		    ;;
		*:open-mpi/ge/*|*:openmpi/ge/*)
		    pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		    envSetting="OMPI_MCA_btl=tcp,self,sm; export OMPI_MCA_btl"
		    interconnect=ethernet
		    ;;
		*:lam/*)
		    pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		    envSetting="OMPI_MCA_btl=tcp,self,sm; export OMPI_MCA_btl"
		    interconnect=ethernet
		    ;;
		*:mvapich/*)
		    pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_ib"`
		    interconnect=infiniband
		    ;;
		*)
		    pbsOptionQueue=`fb_determineQueue "${nodes}" "${WALLCLOCKLIMIT}" "_eth"`
		    interconnect=ethernet
		    ;;
	    esac

    # Send mail on job begin, abort and end?
    pbsOptionMail=""
    if [ "$DOSENDMAIL" -eq "1" ]; then
      pbsOptionMail="#PBS -m bae"
    fi
    
    # Let the job depend on another job?
    pbsOptionAfter=""
    if [ "$AFTERJOB" != "" ]; then
      pbsOptionAfter="#PBS -W depend=afterok:$AFTERJOB"
    fi

	    # Check whether we got a valid queue
	    if test -z "${pbsOptionQueue}"; then
		
		if test -z "${interconnect}"; then
		    interconnect=">>!!>> (none set) <<!!<<"
		fi
		
		cat <<EOF 1>&2
$0: Error: No queue available that satisfied the node, wallclock and 
$0: interconnect requirements:
$0:   nodes          >= ${nodes}
$0:   wallclock time >= ${WALLCLOCKLIMIT}
$0:   interconnect    : ${interconnect}
EOF
		testIDsWithErrors="$testIDsWithErrors $testid"
		rm -f $tmpjobfile
		continue
	    else
		echo "$0: Trying to enqueue to <${pbsOptionQueue}>."
	    fi

	    # Now, it is known which is the target queue.
	    # Check whether queue is enabled/disabled.
	    queueState="`qstat -Q $pbsOptionQueue | tail -1 | awk '{print \$4}'`"
	    if [ "$queueState""x" = "nox" ]; then
		cat <<EOF 1>&2
$0: Error: Queue $pbsOptionQueue is currently closed, job scheduling
$0: is not possible. Script cancelled.
EOF
		exit 16
	    fi


	    # Now, create the jobfile.
	    cat <<EOF > $jobfile
#!/bin/sh

#PBS -l walltime=$WALLCLOCKLIMIT
$pbsOptionNodes
#PBS -q $pbsOptionQueue
#PBS -o $PWD/logs/output.$testid
# join standard output and error streams
#PBS -j oe
#PBS -M $EMAILADDRESS
$pbsOptionMail
$pbsOptionAfter

cd $PWD

EOF
	    if [ $? -ne 0 ]; then
		cat <<EOF 1>&2
$0: Error while creating jobfile.
EOF
		rm -f _tmp_.$BENCHMARKRUNSCRIPT.*
		exit 17
	    fi


	    # Add environment settings to jobfile
	    echo "$envSetting" >> $jobfile
	    echo >> $jobfile
	    fb_addModuleInstructions >> $jobfile
	    echo >> $jobfile


	    # Add the content of our runtests script to the jobfile
	    cat $tmpjobfile >> $jobfile
	    rm -f $tmpjobfile;

	    # Make jobfile executable
	    chmod 750 $jobfile

	    echo $0": Jobfile <$jobfile> created."
 	    successfulTests=`expr $successfulTests + 1`

      if [ $NOSCHEDULE -ne "1" ]; then
	      echo $0": Submitting <$jobfile>."
	      # Submit the jobfile. Keep trying to submit it in
	      # case the maximum number of jobs per user is already
	      # reached.
	      fb_submitJobfile "$jobfile" "Maximum number of jobs already in queue"
	    else
	      echo $0": Submitting <$jobfile> skipped."
	    fi
	fi
    done
    trap - 2 3 9;
}




# ================================================
# = Here is where to script really gets executed =
# ================================================

fb_readargs "$@"
fb_ensureCorrectWorkingDir
fb_setMailSender
fb_findGNUMake
fb_queryPBSLiDO
echo


successfulTests=0
testIDsWithErrors=""

# Intelligently create jobfile. Strategy: Bypass the usual mechanism
# involving repeated calls of 'make singletest' to speed up processing.
#
# Takes 2min for 560 tests.
fb_fastCreateAndSubmitJobfilesLiDO "$JOBFILEPREFIX"
# Show error messages, if any
fb_postprocess "$successfulTests" "$testIDsWithErrors"

# # Create jobfiles one by one. Basically following the strategy:
# #       for testid in $ALLTESTS
# #           echo $testid > singletest.fbconf
# #           make singletest
# #           rm -f singletest.fbconf
# #       done
# # Takes 13min for 560 tests.
# for testid in $ALLTESTS
# do
#     jobfile="$JOBFILEPREFIX.$testid.sh"
#     echo $0": Creating jobfile for <$testid>."
#     fb_createJobfileLiDO "$testid" "$jobfile"
#     if [ $? -eq 0 ]; then
# 	successfulTests=`expr $successfulTests + 1`
# 	echo $0": Submitting <$jobfile>."
# 	# Submit the jobfile. Keep trying to submit it in
# 	# case the maximum number of jobs per user is already
# 	# reached.
# 	fb_submitJobfile "$jobfile" "Maximum number of jobs already in queue"
#     else
# 	echo $0": An error occurred creating the jobfile. Submit cancelled."
# 	testIDsWithErrors="$testIDsWithErrors $testid"
#     fi
#     echo
# done
# # Show error messages, if any
# fb_postprocess "$successfulTests" "$testIDsWithErrors"
